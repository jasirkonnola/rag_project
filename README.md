# ğŸ“š Django RAG PDF Q&A Project

A simple Retrieval-Augmented Generation (RAG) system built with **Django**, **FAISS**, and **Ollama (LLaMA 3)**.  
It allows users to upload PDFs, automatically indexes their content into a vector store, and then ask natural language questions about the document.

---

## ğŸš€ Features
- Upload PDF files via a web interface.
- Extract text and split into chunks.
- Store embeddings in a FAISS vector database.
- Query the vector store with natural language questions.
- Get answers generated by **LLaMA 3** running locally via Ollama.

---

## ğŸ› ï¸ Tech Stack
- **Django 5.2.9** â€“ Web framework
- **LangChain** â€“ Orchestration
- **FAISS** â€“ Vector store
- **HuggingFace Sentence Transformers** â€“ Embeddings
- **Ollama (LLaMA 3)** â€“ Local LLM for answering questions
- **PyMuPDF** â€“ PDF text extraction

---

## âš™ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/rag_project.git
   cd rag_project

# Create and activate a virtual environment:
python -m venv tfenv
# Linux/Mac
source tfenv/bin/activate
# Windows
tfenv\Scripts\activate

# Install dependencies:
pip install -r requirements.txt

# Run migrations:
python manage.py migrate

# Start the server:
python manage.py runserver

## ğŸ“‚ Project Structure
rag_project/
â”œâ”€â”€ rag_app/
â”‚   â”œâ”€â”€ templates/rag_app/
â”‚   â”‚   â”œâ”€â”€ base.html
â”‚   â”‚   â””â”€â”€ upload.html
â”‚   â”œâ”€â”€ static/rag_app/css/style.css
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”‚   â”œâ”€â”€ text_splitter.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â””â”€â”€ embeddings.py
â”‚   â”œâ”€â”€ views.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ rag_project/
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ wsgi.py
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ“– Usage
1.Go to http://127.0.0.1:8000/.
2.Upload a PDF file.
3.Ask a question in the input box.
4.Get an answer based on the PDF content.

## âœ… Requirements
- Python 3.10+
- Django 5.2.9
- FAISS (faiss-cpu)
- LangChain (langchain, langchain-community, langchain-huggingface, langchain-ollama)
- HuggingFace Sentence Transformers (sentence-transformers)
- PyMuPDF (pymupdf)

# Ollama with llama3 model installed:
  ollama pull llama3

## ğŸ“ Notes
- Make sure Ollama is running locally before asking questions.
- The FAISS index is saved in faiss_index/.
- For production, configure .env for secrets and database settings.
- Add .env, db.sqlite3, media/, and tfenv/ to .gitignore before pushing to GitHub.
- 
